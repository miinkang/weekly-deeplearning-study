# 자연어처리가 필요한 이유
**"Alice drove down the street in her car."**   
해당 문장은 중의적인 의미로 해석할 수 있습니다.   
1. 차를 운전해서 거리를 달리고 있다.
2. 차 안의 거리를 달리고 있다.    

물론 이 글을 읽는 우리(사람)은 거리가 차 안에 있지 않다는 사실을 알고 있기 때문에, 1번의 의미로 해석을 바로 할 수 있다.
하지만, 이 글을 컴퓨터가 해석한다면 어떨까?   
우리가 아는 사전 정보(거리는 차 안에 있지 않다)를 전달해 단어의 의미를 파악하게 해야한다.    

이처럼 컴퓨터가 사람처럼 자연어를 처리할 수 있도록 전처리해주는 방법에 대해서 정리하고자 한다. 

# 노이즈 제거
모델에서 학습해야하는 자연어 데이터는 교과서의 문장처럼 정제되어있지 않다. 축약어나 맞춤법이 틀리는 경우 등이 있는데 이런 변형된 데이터를 **노이즈**라고 한다. 
- 노이즈의 종류   
    - 문장부호
    - 대소문자 (영어)
    - 특수문자

# 분산표현(distributed representation)과 희소표현(Sparse representation)

## 희소표현 
벡터의 각 차원마다 단어의 특정 의미 속성을 대응시키는 방식    
단어를 **고차원 벡터**로 변환    
ex) 여자[1], 남자[-1]이고 나이적음[-1], 나이많음[1]이라면 할머니=[1, 1], 할아버지=[-1, 1]로 표현된다.       

**희소표현의 단점**   
1. 여러가지 속성을 표현하려면 차원이 너무 많아진다. 
2. 워드 벡터끼리 단어들 간의 의미적 유사도를 계산할 수 없다. 
---
## 분산표현 
비슷한 위치에서 등장하는 단어들은 비슷한 의미를 가진다(분포 가설)이라는 가정 하에 만들어진 표현 방법   
벡터에 단어의 의미를 여러 차원에 분산하여 표현한다.   

**분산표현의 장점**   
1. 벡터의 차원이 단어 집합의 크기일 필요가 없다. 상대적으로 저차원으로 줄어든다.
2. 저차원에 단어의 의미를 여러 차원에다가 분산하기 때문에 단어 간 유사도를 계산할 수 있다.   

위와 같은 장점으로 분산표현은 몇 차원으로 구성할 지 조절할 수 있다.

# 토큰화
문장을 특정 기준으로 나누어 단어 단위로 바꾸는 것    

## 토큰화의 종류
1. 공백 기반 토큰화
2. 형태소 기반 토큰화   

## 사전에 없는 단어는 어떻게 처리할까?
이 경우 \<unk>, \<oov> 등 특수한 토큰으로 치환한다.    
\<unk> : unknown의 약자   
\<oov> : out of vocabulary의 약자 

# 토큰화의 기법 
## Byte Pair Encoding(BPE)
한 단어를 여러 개의 Subword의 집합으로 보는 방법   
데이터에서 **가장 많이 등장하는 바이트 쌍(Byte Pair)**을 **새로운 단어로 치환**하여 압축하는 작업을 반복하는 방식    

**특징**
- 모든 단어를 문자의 집합으로 취급
- 접두어, 접미어의 의미를 캐치할 수 있다.
- 처음 등장하는 단어 또한 문자들의 조합으로 나타내기 때문에 OOV문제 해결 가능 
---
## Wordpiece Model(WPM)
*구글에서 BPE를 변형해 제안한 알고리즘이라고 한다.*   

**특징**
- 공백 복원을 위해 단어의 시작 부분에 '_' 를 추가한다. 
- 빈도수 기반이 아닌 가능도(LIkelihood)를 증가시키는 방향으로 문자 쌍을 합친다.   

> 잠깐 ! 가능도(Likelihood)란 무엇일까?   
- 어떤 값이 관측되었을 때, 어떤 확률 분포에서 왔을 지에 대한 확률   
- 즉, 확률의 확률이라고 할 수 있다.   

**장점**
- 한국어처럼 조사, 어미 등의 활용이 많은 언어를 토큰화하기에 좋다.
- 하지만, 한국어 뿐만 아니라 모든 언어에 적용할 수 있는 general한 기법이다. 
